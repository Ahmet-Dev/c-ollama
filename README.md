#C-Ollama: AI-Powered Code Assistant for VS Code
C-Ollama is a powerful, multi-model VS Code extension that integrates seamlessly with Ollama to provide an AI-powered code assistant. It helps developers write cleaner, SOLID-compliant code through an intuitive chat interface, automation workflows, and advanced code management features.

#Key Features
üó£Ô∏è AI-Powered Chat Interface
Engage in rich conversations with the AI to assist in writing, refactoring, and debugging your code.
Message history and conversation management to ensure easy navigation.
AI-generated code is written directly into files, streamlining the coding process.
‚öôÔ∏è Automation Workflows
Create, edit, delete, and manage automated tasks for repetitive coding actions.
Automations can be run continuously at configurable intervals to boost productivity.
Automations are saved in automations.json for easy access and reusability.
üìÇ File Operations
Create, update, delete, and modify files according to your project needs.
Supports drag-and-drop functionality for files and folders, along with a file upload button.
Multi-file selection for bulk operations.
üõ†Ô∏è Multi-Model Workflow
Chat Model: Interact with the AI using natural language to discuss your coding requirements.
Design Model: Get SOLID-compliant solutions for your coding challenges, ensuring clean architecture.
Code Model: Implement your solutions step-by-step while managing token limits to break down complex tasks into manageable chunks.
üîÑ Code Comparison and Merge
Compare and merge AI-generated code with your existing codebase, helping maintain consistency and quality.
Use the "Go Back" button to revert any AI-generated changes if needed.
‚öôÔ∏è Settings Management
Configure Ollama server settings, models, and parameters for a personalized experience.
Settings are stored in settings.json for easy management and portability.
üíº Professional UI
Fully integrated with VS Code‚Äôs native UI with dedicated panels for Chat, Automations, and Settings.
Enhanced branding with a sleek logo and favicon for a polished, professional experience.
üß† Token Management
Automatically creates folders and files based on the needs of your project.
Operations are staged and can be reverted if necessary, ensuring flexibility and safety.
Token limits are effectively managed to break down large tasks into smaller, more manageable steps.
Usage
Open the C-Ollama panel from the activity bar.
Start chatting with the AI to discuss your coding tasks and get assistance.
Create automations for repetitive tasks, and set them to run continuously at configurable intervals.
Configure the settings to customize the extension for your specific needs and workflow.
Installation
Install the extension from the VS Code Marketplace.
Configure the settings to connect to your Ollama API.
Start using C-Ollama to boost your productivity and write SOLID-compliant code faster.
Enhanced Features
Right-click Menu Commands:
C-Ollama: Open Chat
C-Ollama: Edit File
C-Ollama: Debug
C-Ollama: Settings
Improved File Handling:
Drag-and-drop support for files and folders.
File upload button for quick file additions.
Multi-file selection for bulk actions.
UI Enhancements:
"Run Terminal Code" button for terminal code execution.
"Go back" button under each assistant message to revert changes.
Tabs for Chat and Automations views.
Token Management
Token limits are managed by breaking down complex tasks into smaller, manageable steps.
Operations are staged, allowing you to control and revert changes if needed.
The extension handles large code changes effectively, ensuring a smooth experience.
Contributing
We welcome contributions to C-Ollama! If you'd like to contribute, feel free to fork the repository, create a branch, and submit a pull request. Please ensure your contributions follow the existing code style and include tests if applicable.

License
This project is licensed under the MIT License - see the LICENSE file for details.

Try it now and revolutionize your coding workflow with C-Ollama!
